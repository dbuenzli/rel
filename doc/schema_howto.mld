{0 Schema management howto}

A few tips on how to manage your database schema with rel.

{1:def Schema definition strategy}

Rel lets you decide where you want to define your database schema.
You can define it either {e internally}, with an OCaml {!Rel.Schema.t}
value or {e externally} using any other tool you may see fit. It is
also possible, to some extent, to move from one strategy to the other.

An internal OCaml definition can always be switched to an external
one. The {!Rel_sql.create_schema} function generates legible SQL
data definitions from a {!Rel.Schema.t} value in the dialect of your
database management system (DBMS). Would you need to move away
from rel this {e always} works.

An external schema definition can be moved to an OCaml one by
connecting to your database and generating the OCaml code for a
{!Rel.Schema.t} value representing it. The [rel] command line tool or
(e.g.) {!Rel_sqlite3.schema_of_db} and {!Rel.Schema.pp_ocaml} can be
used for that. However if the external schema definition uses features
that cannot be expressed by a {!Rel.Schema.t} value, it is not
posssible to faithfully represent and regenerate the external schema
from the generated OCaml schema – it is nevertheless useful to query
the database with rel.

Ultimately which solution you choose depends on the degree of control
you need over your DBMS. Since {!Rel.Schema.t} abstracts over DBMS and
their differences, you may find yourself limited by sticking to an
OCaml internal definition. Though using {{!page-sql_stmt_howto} raw
SQL statements} can bring you a long way.

{1:changes Schema changes}

The goal of a schema change is to make the {e live schema} (which can
be captured for example with {!Rel_sqlite3.schema_of_db}) of a
database instance to coincide with the {e application's schema}, that
is the schema that your software is assuming to hold.

Rel provides support to compute the change between a source and
destination {!Rel.Schema.t} value. Table and column renames need
however to be provided manually. The [rel changes] command or
the {!Rel.Schema.val-changes} function perform this.

This allow to compute the changes needed by your live database to
bring it to the schema you need.

These changes can be turned into SQL data definition statements with
the {!Rel_sql.schema_changes} functions to apply on a source
schema to bring it to the destination schema. Note that this only
handles structural changes to the database. You may need to provide
additional statements to handle data migrations. You should also
always have a careful look at these steps and possibly tweak them,
especially if you do this with externally defined schemas.

{2:single Single live database instance or development mode}

- Let [dst] be the application database's schema.
- Let [src] be the the live database schema.
- Derive the steps to move from [src] to [dst].
- If the steps are empty, your live database is up-to-date. Otherwise
  {b check} the steps, make a backup of your database and apply the
  steps to the live schema.

{2:released Released schemas}

In this case we need to version the schema. The way to do this is DBMS
dependent. Here a few ways:

- Use the {{:https://www.sqlite.org/pragma.html#pragma_user_version}
  [user_version] pragma} for sqlite3.

The application keeps the latest version of the schema and diff steps
to go from earlier versions to the next version until the latest one.

Before interacting with the database:

- Get the version of the live database.
- Apply the steps to go the next version until the application database
  version is reached.

{1:conventions Schema conventions}

There's more than one way to model your database in OCaml with [Rel].
The following defines a simple conventions you can follow.

These conventions is followed by the [rel] tool when it outputs
the OCaml code needed to support interaction with an externally defined
database schema, except for the naming conventions which respect those
found in the existing schema.

{2:names Names}

{ul
{- Table names, keep them singular, lower and snake cased.}
{- Column names, keep them lower, snake cased. Have the primary key
   as the first column and then unless there are few of them
   sort them in alphabetical order.}
{- Relations, use the related table names seperated by a [_] to name them.}
{- Indices, use the table name and the indexed columns separated by
   a [_]. {!Rel.Table.Index} does this for you automatically if you don't
   specify a name for the index.}}

{2:table Tables representation}

Given a table named {e n} with columns {e c{_0}, c{_1}, …} define a
module [N] ({e n} capitalized) for it.  This module should have

{ul
{- An abstract type [N.t] for representing table rows.}
{- An [N.row] constructor for the row with arguments in the order of columns.}
{- (Optional) A user friendly [N.v] constructor with labelled arguments.}
{- Accessors [N.c]{_i} projecting the corresponding column {e c{_i}}
   from [N.t] values.}
{- Values [N.c']{_i} of type {!Rel.Col.t} for each corresponding
   column {e c{_i}}.}
{- A value [N.table] of type {!Rel.Table.t} that defines the table.}}

Once you have modelled your tables and gathered them into a schema
values with {!Rel.Schema.v} you can use {!Rel_sql.create_schema} to
output the corresponding schema in SQL's data definition language.

{2:example Example}

Consider a [person] table which has three columns [id] and
[first_name] and [last_name] columns. The following interface
represents such a table according to the convention.

{[
(** Persons. *)
module Person : sig

  type id = int
  (** The type for person identifiers. *)

  type t
  (** The type for persons. *)

  val v : id:id -> first_name:string -> last_name:string -> t
  (** [v ~id ~first_name ~last_name] is a person with given attributes.
      See accessors for semantics. *)

  val row : int -> string -> string -> t
  (** [row] is unlabelled {!v}. *)

  val id : t -> id
  (** [id p] is the unique identifier of [p]. *)

  val first_name : t -> string
  (** [first_name p] is the first name of [p]. *)

  val last_name : t -> string
  (** [last_name p] is the last name of [p]. *)

  (** {1:table Table} *)

  open Rel

  val id' : (t, id) Col.t
  (** [id'] is the {!id} column. *)

  val first_name' : (t, string) Col.t
  (** [first_name'] is the {!first_name} column. *)

  val last_name' : (t, string) Col.t
  (** [last_name'] is the {!last_name} column. *)

  val table : t Table.t
  (** [table] is the person table. *)
end
]}

The simplest way of implementing this signature is by using OCaml records.
For example:

{[
module Person = struct
  type id = int
  type t = { id : id; first_name : string; last_name : string }

  let v ~id ~first_name ~last_name = { id; first_name; last_name }
  let row id first_name last_name = { id; first_name; last_name }

  let id r = r.id
  let first_name r = r.first_name
  let last_name r = r.last_name

  open Rel

  let id' = Col.v "id" ~params:[Col.Primary_key] Type.Int id
  let first_name' = Col.v "first_name" Type.Text first_name
  let last_name' = Col.v "last_name" Type.Text last_name

 let table =
   Table.v "person" Row.(unit row * id' * first_name' * last_name')
end
]}

{2:alt Alernate direction}

An alternate direction could be to simply define abstract types for
tables but simply have them as generic column map (i.e. heterogenous
dictionary). Could have less boiler plate and less gc pressure since
we do pack {!Rel.Col.value}s at the IO boundary anyways.

{1:unsupported Unsupported DBMS features}

A few DBMS features that would be nice to have but are not supported
at the moment.

For SQLite3.

- Generating SQLite {{:https://www.sqlite.org/stricttables.html}
  strict table} would be nice. However if we do so we can no longer
  distinguish between [bool], [int] and [int64] columns.
- Tables. Table options. [CHECK] constraints on tables. First needs a
  story for SQL expressions. Second in SQLite3 AFAIK it's not possible
  to get it from the meta tables. This means we would have to parse
  the SQL CREATE statements for {!Rel_sqlite3.schema_of_db} which
  we avoided so far.
- Indices. partial indexes.
- Views. Virtual tables. Triggers
- Column constraints. Some are supported at the table level (primary
  key, unique, foreign keys) or the type level (not null). But we are
  missing COLLATE, GENERATED, AUTOINCREMENT.
- Primary keys ASC/DESC.
